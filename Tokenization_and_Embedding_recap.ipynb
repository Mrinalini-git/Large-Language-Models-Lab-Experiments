{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21f31e5424864f72ae85d3c139fb169d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75ac2206559c4602a821d32a20869c91",
              "IPY_MODEL_5b6d653d9183490cab1735facd7f69ef",
              "IPY_MODEL_37c1498eeda14bffabf31fbecadbe02e"
            ],
            "layout": "IPY_MODEL_6e9f4d0656564136bb0330b0a5d74cec"
          }
        },
        "75ac2206559c4602a821d32a20869c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563a693f6a2647559d3a412e86e20bc4",
            "placeholder": "​",
            "style": "IPY_MODEL_3803e546f5724efca2f8385525a4bd0d",
            "value": "Loading weights: 100%"
          }
        },
        "5b6d653d9183490cab1735facd7f69ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e3be090526419d8ecf1ec8ccabfb74",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0340d96a4afb4ee3a98ba6ed9e101e3d",
            "value": 199
          }
        },
        "37c1498eeda14bffabf31fbecadbe02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4839037a5cea465e899f360ae334fb62",
            "placeholder": "​",
            "style": "IPY_MODEL_a801670f19b248f98488b264e017ca1f",
            "value": " 199/199 [00:00&lt;00:00, 473.91it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "6e9f4d0656564136bb0330b0a5d74cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563a693f6a2647559d3a412e86e20bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3803e546f5724efca2f8385525a4bd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e3be090526419d8ecf1ec8ccabfb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0340d96a4afb4ee3a98ba6ed9e101e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4839037a5cea465e899f360ae334fb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a801670f19b248f98488b264e017ca1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7a00c01",
        "outputId": "526d5ec2-9923-4936-c1e2-3a7716d6c669"
      },
      "source": [
        "# Install the transformers library if you haven't already\n",
        "%pip install transformers\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined_cell",
        "outputId": "0d8c6e7b-77b5-4d92-d2e9-5471927465f2"
      },
      "source": [
        "print(\"--- Combined Tokenization and Embedding --- \")\n",
        "sentence_for_all = input(\"Enter a sentence to process: \")\n",
        "\n",
        "# Perform Word Tokenization\n",
        "perform_word_tokenization(sentence_for_all)\n",
        "\n",
        "# Perform Sub-word Tokenization\n",
        "perform_subword_tokenization(sentence_for_all)\n",
        "\n",
        "# Generate and Display Embedding\n",
        "generate_sentence_embedding(sentence_for_all)\n",
        "\n",
        "print(\"------------------------------------------\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combined Tokenization and Embedding --- \n",
            "Enter a sentence to process: Every moment is a beginning.\n",
            "\n",
            "Original Sentence (Word Tokenization): Every moment is a beginning.\n",
            "Word Tokens: ['Every', 'moment', 'is', 'a', 'beginning', '.']\n",
            "\n",
            "Original Sentence (Sub-word Tokenization): Every moment is a beginning.\n",
            "Sub-word Tokens: ['every', 'moment', 'is', 'a', 'beginning', '.']\n",
            "\n",
            "Original Sentence (Embedding): Every moment is a beginning.\n",
            "Shape of sentence embedding: torch.Size([768])\n",
            "Sentence Embedding (first 10 dimensions): tensor([ 0.0380,  0.3059, -0.2016,  0.1223, -0.6078, -0.3073,  0.2931,  0.5669,\n",
            "         0.3546, -0.7233])\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90d968be"
      },
      "source": [
        "### What is Tokenization?\n",
        "\n",
        "Tokenization is the process of breaking down a text into smaller units called \"tokens.\" These tokens can be words, subwords, or even characters, depending on the tokenization method. It's a fundamental step in Natural Language Processing (NLP).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44dfce87"
      },
      "source": [
        "### 1. Word Tokenization\n",
        "\n",
        "Word tokenization involves splitting text into individual words. This is often the simplest form of tokenization. We will use the `nltk` library for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5281468c",
        "outputId": "55cc7502-b5fa-4aeb-e604-29b27eb841f6"
      },
      "source": [
        "# Install NLTK if you haven't already\n",
        "%pip install nltk\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "626b5736",
        "outputId": "38a64c47-0a13-48d9-e255-134061d857bb"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Download the 'punkt' tokenizer models, which are necessary for word tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download 'punkt_tab' to resolve the LookupError"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eafade13"
      },
      "source": [
        "### 2. Sub-word Tokenization\n",
        "\n",
        "Sub-word tokenization breaks words into smaller units (sub-words). This is useful for handling out-of-vocabulary words, reducing vocabulary size, and capturing morphological information. We will use a pre-trained tokenizer from the `transformers` library (specifically, a BERT tokenizer) for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f689adb4"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def perform_word_tokenization(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    print(\"\\nOriginal Sentence (Word Tokenization):\", sentence)\n",
        "    print(\"Word Tokens:\", tokens)\n",
        "\n",
        "# The function will be called from the combined cell."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20825614"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load a pre-trained BERT tokenizer\n",
        "# You can choose other models like 'RobertaTokenizer', 'XLNetTokenizer', etc.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def perform_subword_tokenization(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    print(\"\\nOriginal Sentence (Sub-word Tokenization):\", sentence)\n",
        "    print(\"Sub-word Tokens:\", tokens)\n",
        "\n",
        "# The function will be called from the combined cell."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ea65c10"
      },
      "source": [
        "### 3. Creating Embeddings\n",
        "\n",
        "Embeddings are numerical representations of text that capture semantic meaning. We'll use the pre-trained BERT model to generate these for a given sentence. These embeddings are often used as input for various downstream NLP tasks like sentiment analysis, text classification, or semantic search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "21f31e5424864f72ae85d3c139fb169d",
            "75ac2206559c4602a821d32a20869c91",
            "5b6d653d9183490cab1735facd7f69ef",
            "37c1498eeda14bffabf31fbecadbe02e",
            "6e9f4d0656564136bb0330b0a5d74cec",
            "563a693f6a2647559d3a412e86e20bc4",
            "3803e546f5724efca2f8385525a4bd0d",
            "80e3be090526419d8ecf1ec8ccabfb74",
            "0340d96a4afb4ee3a98ba6ed9e101e3d",
            "4839037a5cea465e899f360ae334fb62",
            "a801670f19b248f98488b264e017ca1f"
          ]
        },
        "id": "99299f22",
        "outputId": "998d7bcf-fe45-4f57-94bb-76f4ffbac780"
      },
      "source": [
        "from transformers import BertModel\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained BERT model\n",
        "# We use 'output_hidden_states=True' to get all hidden states, including embeddings\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "model.eval() # Set the model to evaluation mode\n",
        "\n",
        "def generate_sentence_embedding(sentence):\n",
        "    # Tokenize the sentence and get input IDs and attention mask\n",
        "    encoded_input = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation for inference\n",
        "        output = model(**encoded_input)\n",
        "\n",
        "    # The last hidden state contains the contextualized embeddings for each token\n",
        "    last_hidden_state = output.last_hidden_state\n",
        "\n",
        "    # For sentence embedding, often the embedding of the [CLS] token (first token) is used\n",
        "    # Alternatively, you could average all token embeddings or use other pooling strategies\n",
        "    sentence_embedding = last_hidden_state[:, 0, :].squeeze()\n",
        "\n",
        "    print(\"\\nOriginal Sentence (Embedding):\", sentence)\n",
        "    print(\"Shape of sentence embedding:\", sentence_embedding.shape)\n",
        "    print(\"Sentence Embedding (full tensor):\", sentence_embedding)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "# The function will be called from the combined cell."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21f31e5424864f72ae85d3c139fb169d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: bert-base-uncased\n",
            "Key                                        | Status     |  | \n",
            "-------------------------------------------+------------+--+-\n",
            "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
            "cls.predictions.bias                       | UNEXPECTED |  | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29611d26",
        "outputId": "33e34f25-7ce3-44e2-de55-77464afeb563"
      },
      "source": [
        "print(\"--- Combined Tokenization and Embedding --- \")\n",
        "sentence_for_all = input(\"Enter a sentence to process: \")\n",
        "\n",
        "# Perform Word Tokenization\n",
        "perform_word_tokenization(sentence_for_all)\n",
        "\n",
        "# Perform Sub-word Tokenization\n",
        "perform_subword_tokenization(sentence_for_all)\n",
        "\n",
        "# Generate and Display Embedding\n",
        "generate_sentence_embedding(sentence_for_all)\n",
        "\n",
        "print(\"------------------------------------------\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Combined Tokenization and Embedding --- \n",
            "Enter a sentence to process: Every moment is a begiinning\n",
            "\n",
            "Original Sentence (Word Tokenization): Every moment is a begiinning\n",
            "Word Tokens: ['Every', 'moment', 'is', 'a', 'begiinning']\n",
            "\n",
            "Original Sentence (Sub-word Tokenization): Every moment is a begiinning\n",
            "Sub-word Tokens: ['every', 'moment', 'is', 'a', 'beg', '##ii', '##nni', '##ng']\n",
            "\n",
            "Original Sentence (Embedding): Every moment is a begiinning\n",
            "Shape of sentence embedding: torch.Size([768])\n",
            "Sentence Embedding (full tensor): tensor([-1.5569e-01,  2.1537e-01,  1.0082e-01, -5.5937e-02, -2.8631e-01,\n",
            "        -1.9818e-01,  1.3434e-01,  3.7674e-01,  2.1692e-02, -4.3172e-01,\n",
            "        -7.1860e-02,  2.7242e-02,  1.5415e-01,  2.8584e-01,  1.6479e-01,\n",
            "        -2.3501e-02,  4.6647e-02,  3.2918e-01,  4.3362e-02, -1.9999e-01,\n",
            "        -1.0753e-01, -5.3640e-02,  8.6403e-02, -8.7758e-02, -2.5036e-02,\n",
            "        -1.0619e-01, -5.5695e-03, -1.8419e-01,  2.7631e-02,  3.1525e-01,\n",
            "         2.1008e-01,  1.8959e-01, -1.8626e-02, -1.1821e-01, -6.4337e-03,\n",
            "        -6.7946e-02,  2.0067e-01, -1.4722e-01,  3.8264e-02,  1.3043e-02,\n",
            "         9.4228e-02,  1.6205e-01,  1.1620e-01, -7.2272e-02, -1.4152e-02,\n",
            "        -3.3615e-01, -1.9576e+00,  7.4744e-03, -1.7686e-01, -1.0538e-01,\n",
            "        -1.3741e-02,  2.0348e-02,  5.3058e-01,  1.6674e-01,  1.5357e-02,\n",
            "         1.5728e-01, -3.0194e-01,  7.9693e-01,  1.6478e-01, -4.0013e-02,\n",
            "         1.0426e-01, -8.0336e-02,  1.7982e-01,  1.5348e-01, -1.4081e-01,\n",
            "         2.4894e-01,  8.8938e-02,  1.1188e-01, -5.1215e-02,  4.0109e-01,\n",
            "        -2.8523e-01, -3.0452e-01,  2.4256e-01, -1.1529e-01,  1.8250e-02,\n",
            "        -1.7747e-01, -5.4158e-02,  1.5450e-01,  2.1483e-02,  5.6666e-02,\n",
            "         2.2841e-01,  3.4900e-01,  2.3773e-01, -5.1778e-03,  1.0829e-01,\n",
            "         1.1646e-01, -5.9393e-02, -2.1350e-01,  1.5895e-01,  3.8449e-01,\n",
            "        -1.6494e-01,  8.2040e-02,  1.3250e-01,  3.8093e-01,  7.1516e-02,\n",
            "        -5.1636e-01,  1.0374e-01, -4.3701e-02,  1.3110e-01,  3.1439e-01,\n",
            "        -1.5595e-02, -6.9499e-02,  1.4611e-01, -3.8832e-01,  7.6042e-02,\n",
            "         1.0630e-01, -1.7704e-01, -1.9165e-01,  2.9142e-01, -2.7428e+00,\n",
            "         2.1999e-01,  9.8633e-02, -7.4631e-02, -1.4922e-02, -1.1347e-01,\n",
            "         2.2665e-01,  1.5286e-01,  7.3298e-02,  1.3487e-01, -1.7872e-01,\n",
            "        -5.6072e-02,  2.0677e-01,  2.8532e-01, -1.2143e-01,  2.2680e-01,\n",
            "         1.5245e-01,  4.0007e-02, -3.4703e-01, -3.8161e-02,  1.8561e-01,\n",
            "         8.0963e-03,  3.7487e-01,  7.3937e-02, -2.9334e-01,  8.1077e-05,\n",
            "        -1.5270e-01,  2.6464e-01, -3.5886e-02,  1.2653e-01, -6.3738e-02,\n",
            "        -1.1783e-01,  4.7620e-02, -3.1015e+00,  2.8595e-01,  3.7971e-01,\n",
            "        -1.0995e-01, -2.9332e-01, -2.8707e-01,  9.5204e-02, -1.9694e-01,\n",
            "        -7.7818e-02,  2.0323e-01, -1.2876e-02,  3.7584e-02, -1.4747e-01,\n",
            "        -4.7937e-01,  1.1608e-02, -4.3439e-02,  4.7542e-01,  3.0577e-01,\n",
            "         3.9244e-02, -2.9405e-01,  3.0979e-01, -1.9003e-01, -3.0307e-01,\n",
            "        -2.9247e-01,  2.6276e-01,  2.9850e-01,  5.9979e-02, -1.3537e-01,\n",
            "        -1.8004e-01,  1.8254e-01,  2.7901e-01,  1.8441e-01,  2.3591e-01,\n",
            "        -9.3618e-02,  2.6171e-01,  1.4217e-01,  2.5415e-02, -1.1724e-01,\n",
            "        -1.9439e-01,  3.6481e-01,  4.5822e-02, -1.4466e-01,  2.0267e-01,\n",
            "         8.3309e-03,  1.1822e-01, -1.7142e-01, -2.2250e-01,  3.8222e-01,\n",
            "        -1.9089e-01,  4.5556e-02,  2.7933e-01, -1.9233e-01,  2.5292e-01,\n",
            "        -2.1857e-01,  1.4738e-01, -4.0528e-01,  2.3626e-01,  1.9064e-01,\n",
            "         5.6775e-02, -9.4957e-02, -4.2641e-01, -1.1183e-01, -7.9982e-02,\n",
            "         3.9431e+00,  1.2370e-01, -2.0179e-01,  2.8014e-01, -1.9713e-01,\n",
            "        -1.6284e-01,  1.8457e-01, -3.7734e-02,  7.9296e-02, -1.8525e-01,\n",
            "        -1.8434e-01,  3.3771e-01, -4.1865e-02, -1.2877e-01,  1.1165e-03,\n",
            "         4.4002e-01,  1.6070e-01, -1.0233e-01, -1.0597e-01, -2.9078e-01,\n",
            "        -2.7077e-03,  1.4998e-01, -8.9846e-02, -3.6337e-02, -1.2158e+00,\n",
            "         5.1166e-02, -1.6786e-01, -3.8367e-01,  2.6828e-01, -5.4419e-03,\n",
            "         1.2548e-01,  1.0821e-01, -1.7344e-01,  1.2134e-01,  3.0979e-02,\n",
            "        -2.6317e-03,  9.6017e-02,  1.3404e-01,  2.9375e-01, -1.1646e-01,\n",
            "         5.6675e-01,  4.7223e-01, -1.0723e-01,  1.5926e-01,  8.7138e-02,\n",
            "         2.8392e-01, -1.6007e-01, -9.9117e-02, -1.0690e-01, -1.0304e-01,\n",
            "        -9.0197e-02,  1.0473e-02, -1.3702e-01, -1.0229e-01,  1.3411e-01,\n",
            "        -3.0766e-01, -4.2841e-02,  2.4035e-01,  2.4818e-02, -2.5395e-01,\n",
            "        -3.3670e-02,  5.0257e-02, -3.0919e-01,  3.6472e-01,  5.2925e-02,\n",
            "         1.4261e-01, -5.3867e-02, -2.1598e-01, -4.3057e+00,  7.6118e-02,\n",
            "         2.8841e-01,  5.1272e-01,  1.7566e-01, -1.1022e-01,  7.1152e-02,\n",
            "         2.4105e-01,  1.4278e-01, -3.6038e-01,  2.8772e-01,  2.6819e-01,\n",
            "        -1.3660e-01,  6.2328e-01, -3.2888e-01,  2.5445e-01,  3.0310e-01,\n",
            "        -6.0796e-02,  1.9531e-01,  4.7662e-02,  2.1439e-01,  2.4405e-01,\n",
            "        -3.0552e-01, -7.0235e-02, -7.2477e-04, -2.6078e-01, -1.9476e-01,\n",
            "        -4.7303e-03,  2.1784e-01,  1.0622e-01,  4.9807e-02,  4.4816e-02,\n",
            "        -1.4511e-01,  7.4075e-02,  4.8395e-02, -3.2114e+00,  2.3916e-02,\n",
            "         4.4573e-02, -5.0367e-02,  1.7747e-01, -2.3993e-01,  1.8971e-01,\n",
            "         1.0906e-01, -2.0488e-01, -8.4239e-02, -1.1663e-01, -4.1503e-02,\n",
            "         1.1864e-01,  2.8477e-01,  2.2787e-01, -3.8811e-01, -3.6792e-02,\n",
            "         7.8385e-02, -6.3443e-02, -1.9742e-02, -2.9498e-01,  8.6674e-02,\n",
            "         1.9360e-01, -1.7179e-01, -1.2160e-01,  1.5470e-01, -3.3457e-01,\n",
            "        -2.5767e-01, -2.1543e-01, -6.1861e-02, -2.0737e-01, -2.2649e-01,\n",
            "         1.0058e-01, -2.4919e-01, -3.0299e-01, -2.0351e-01,  1.6261e-01,\n",
            "         5.9033e-02,  4.1556e-01, -3.0367e-02, -1.9894e-02,  3.2577e-01,\n",
            "         2.1728e-01,  3.9418e-01,  5.0431e-02,  1.3288e-02, -1.8150e-01,\n",
            "        -3.8449e-01, -1.6593e-02,  2.5330e-01, -4.9612e-02,  1.9881e-02,\n",
            "         1.1159e+00, -2.6271e-01, -7.1801e-02, -5.2077e-02,  6.4885e-02,\n",
            "        -2.4674e-02,  2.0491e-01,  8.6880e-02,  4.2871e-01,  1.7120e-03,\n",
            "         9.7913e-02,  6.9228e-02, -1.0573e-01, -2.0039e-01,  1.5166e-01,\n",
            "        -2.3909e-01, -1.0716e-01,  2.2561e-01, -9.2937e-03,  2.1946e-01,\n",
            "        -2.7845e-02, -8.6348e-01,  4.0260e-02,  1.9283e-01, -3.8778e-01,\n",
            "         2.0830e-01,  2.9942e-01, -1.8402e-01, -6.8714e-02, -2.6271e-01,\n",
            "         1.0384e-01,  3.4364e-01, -2.3777e-01, -3.0995e-01,  7.6389e-02,\n",
            "        -1.2699e-02, -1.8796e-01,  8.2857e-02, -2.5732e-02,  1.8609e-01,\n",
            "         9.7054e-02, -1.0830e-01,  1.1360e-01,  2.5792e-01,  2.5641e-01,\n",
            "        -6.2384e-01,  1.8879e-01,  1.0347e-02, -8.7469e-02, -3.5505e-01,\n",
            "        -3.2834e-01,  3.2071e-01, -5.4205e-02, -9.0043e-02, -1.8727e-01,\n",
            "         3.4441e-01,  1.1776e-01,  2.4189e-01, -6.8166e-02,  3.7081e-01,\n",
            "         3.9357e-01, -9.1347e-02,  5.3220e-01, -2.7957e-01,  6.6903e-02,\n",
            "         2.8583e-01,  3.1685e-02,  1.0721e-01,  1.6964e-02,  1.0974e-02,\n",
            "         1.6023e-01,  1.0667e-01, -2.9080e-01,  3.9918e-02,  1.1809e-02,\n",
            "        -3.0777e-01, -2.3016e-01, -2.2272e-01, -4.5436e-02, -1.2062e-01,\n",
            "        -2.1238e-01, -7.3887e-01, -3.0528e-01, -2.4401e-01, -6.1785e-03,\n",
            "         2.0283e-01,  1.9874e-01,  9.8111e-02,  3.7870e-01,  5.3357e-02,\n",
            "        -9.7442e-02,  2.9730e-01, -1.3982e-01,  4.4243e-01,  4.8087e-02,\n",
            "         9.7888e-03, -2.2444e-01,  1.8195e-01,  2.8763e-01, -3.1858e-01,\n",
            "         9.3120e-02, -1.0825e-01, -4.6278e-02, -5.6279e-02, -7.4963e-02,\n",
            "        -2.0472e-01,  2.6431e-01,  2.2354e-01, -1.0765e-02,  1.2589e-01,\n",
            "        -1.0618e+00,  1.6801e-01,  1.6793e-01, -2.2037e-02,  1.0425e-01,\n",
            "        -8.9434e-02, -3.3181e-01,  3.4328e-01, -3.4501e-02,  1.9195e-02,\n",
            "        -3.0708e-01,  1.9306e-01, -1.5371e-01, -7.1663e-02, -3.9099e-02,\n",
            "        -1.2395e-01,  3.9331e-01, -1.1217e-01,  3.3453e-02,  2.2654e-01,\n",
            "        -4.1049e-03,  2.0999e-01, -2.0842e-02, -1.1889e-01, -2.7034e-01,\n",
            "        -1.0226e-01, -1.3023e-02,  4.5595e-01, -5.9275e-02,  1.0710e-01,\n",
            "         5.8188e-02, -6.0030e-01, -3.5606e-01, -1.1412e-01, -2.0594e-02,\n",
            "         7.5630e-02,  2.6522e-01, -7.5042e-02,  5.4528e-01,  3.2176e-01,\n",
            "        -2.8264e-01,  3.0283e-01,  2.7668e-01, -1.0311e-01,  3.1725e-01,\n",
            "         3.2044e-01, -4.0930e-01,  9.5471e-02, -6.3610e-02, -2.0209e-01,\n",
            "        -1.7212e-01,  2.8967e-02, -1.1661e-01,  6.0013e-02, -7.2030e-02,\n",
            "        -9.2779e-02,  2.5774e-01, -1.8532e-01,  2.7311e-01, -3.4398e-01,\n",
            "         4.5442e-01, -9.8901e-02,  1.8580e-02,  3.4187e-01, -3.0227e-01,\n",
            "        -4.2131e-01,  2.9893e-01, -1.7290e-01, -1.8083e-02,  1.5281e-01,\n",
            "         1.4744e-03, -1.9139e-01, -1.8691e-01, -1.4813e-01, -3.3216e-01,\n",
            "         3.9499e-01, -1.0010e-01,  1.4642e-01, -6.7517e-03, -2.2950e-01,\n",
            "        -7.8307e-02, -8.5839e-02, -2.8848e-01,  2.3304e-01, -2.2858e-01,\n",
            "        -1.2446e-01, -9.6489e-02,  4.4694e-02, -2.1517e-01, -1.4907e-01,\n",
            "        -1.7627e-01, -2.6512e-01,  4.1372e-01,  2.1166e-01,  4.7082e-02,\n",
            "         1.5071e-01,  2.6371e-01,  6.2249e-02, -1.4374e-01,  1.9719e-03,\n",
            "        -7.6236e-02,  2.6684e-01,  1.9490e-01,  3.3054e-01, -8.8797e-02,\n",
            "         5.9378e-01,  4.4116e-01,  1.7096e-01, -2.6937e-01,  4.5781e-02,\n",
            "        -3.5273e-01, -1.2662e-02, -3.2588e-01,  2.1229e-02, -2.7055e-02,\n",
            "         1.4653e-01,  2.7565e-01, -2.4639e-01,  2.5294e+00,  2.9241e-01,\n",
            "        -3.8389e-02, -3.5248e-02,  1.0411e-01,  5.1090e-02,  2.1165e-01,\n",
            "        -2.8263e-02, -2.4127e-01,  3.3473e-01,  6.8703e-02, -1.6125e-01,\n",
            "         2.5698e-01,  2.0437e-01,  3.1074e-01,  1.8112e-01, -1.4602e-01,\n",
            "        -8.3836e-02, -2.5299e-01, -1.1897e-01, -2.6351e-01,  2.5808e-01,\n",
            "         1.7209e-01, -2.9653e-01,  8.3440e-02,  8.3094e-02,  1.1478e-02,\n",
            "        -8.4271e-02, -2.9811e-01,  1.3024e-01,  1.6507e-01, -5.3994e-04,\n",
            "         8.1583e-02,  2.4466e-01, -1.6906e-01,  3.8094e-01,  1.2570e-01,\n",
            "        -2.8424e-01, -1.7394e-01,  1.7198e-01, -1.8430e-01, -2.3056e-01,\n",
            "         1.4977e-01,  2.7004e-01, -1.2832e-01,  3.8078e-01, -1.2235e-01,\n",
            "         2.2366e-02,  2.6313e-02,  3.3843e-01, -4.7457e-02, -1.0464e-01,\n",
            "        -3.0990e-01,  2.1764e-01, -1.5702e-01, -3.6506e-01,  2.3846e-01,\n",
            "        -7.7754e-02, -4.0733e-01,  4.9589e-01,  2.3131e-01, -6.0128e-02,\n",
            "         4.2189e-01,  5.5887e-02, -1.3897e-01, -8.0879e-02,  3.6843e-02,\n",
            "         2.0368e-01, -5.7073e-02,  6.4490e-03, -2.5748e-01,  2.7233e-01,\n",
            "         2.1378e-01, -1.2817e-02,  2.4187e-01, -3.4251e-02,  5.4646e-01,\n",
            "        -8.6368e-03, -1.7304e-01, -3.3597e+00,  7.7040e-03, -1.7956e-01,\n",
            "        -3.2844e-02,  1.2620e-01,  1.6039e-01,  1.2795e-01, -3.5764e-02,\n",
            "        -4.0243e-01,  7.5447e-02, -2.5965e-02,  3.9463e-01,  2.6924e-01,\n",
            "         3.9373e-01, -1.7472e-02,  1.8897e-01,  6.7385e-02, -2.7414e-01,\n",
            "        -3.3653e-03, -9.1562e-02, -7.7341e-02, -1.6924e-01, -7.1850e-02,\n",
            "        -1.6850e-03, -9.5464e-02,  3.5065e-01, -2.3191e-02,  5.4641e-03,\n",
            "         9.1188e-02,  1.4466e-01,  4.0623e-02,  1.6384e-01,  1.7654e-01,\n",
            "         4.7476e-02, -1.2993e-03, -3.2699e-02,  7.5116e-02, -1.0130e-01,\n",
            "         1.0746e-01,  9.5746e-02,  1.1314e-01,  4.4703e-01, -1.3753e-01,\n",
            "        -1.6353e-02, -1.9453e-01, -4.3053e-02,  2.4828e-01,  5.1552e-03,\n",
            "         7.4304e-02, -2.0182e-01,  7.5263e-02,  1.6116e-01, -8.3274e-02,\n",
            "        -9.5139e-02,  4.5905e-01,  1.4502e-01, -7.4150e-02, -1.7328e-02,\n",
            "         2.4216e-02,  7.6549e-02, -2.7233e-01, -2.3707e-01,  2.0879e-01,\n",
            "        -5.3645e-02,  3.6331e-01, -1.9905e-01, -5.9465e-02, -7.7105e-02,\n",
            "        -1.3561e-02,  1.6070e-01,  7.2521e-02, -4.4209e-02,  3.3648e-01,\n",
            "         1.8761e-01,  1.0673e-01,  3.1045e-01,  3.7235e-01,  1.7007e-01,\n",
            "        -1.0660e-01,  1.3476e-02, -9.4576e-02, -4.5524e-02, -2.2942e-01,\n",
            "        -1.1456e-01,  4.9989e-02, -8.3885e+00, -2.3286e-01, -2.1824e-01,\n",
            "         3.1900e-02,  6.0114e-03, -7.9520e-03,  4.9169e-02, -1.0879e-01,\n",
            "         3.7814e-02,  2.2548e-02, -1.2749e-01,  3.8465e-03,  8.5128e-02,\n",
            "        -1.2979e-01,  1.2410e-01,  3.9049e-01])\n",
            "------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}